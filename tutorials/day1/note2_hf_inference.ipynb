{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jotang1/CyberSec-Public/blob/master/tutorials/day1/note2_hf_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2789b7a",
      "metadata": {
        "id": "b2789b7a"
      },
      "source": [
        "# LLMs in Practice: Inference with Open-Source Models on Hugging Face\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87685bf7",
      "metadata": {
        "id": "87685bf7"
      },
      "source": [
        "## Part 1: Introduction to HuggingFace Ecosystem\n",
        "\n",
        "**What is HuggingFace?**\n",
        "- The Hub hosts models, datasets, and Spaces with rich model cards and licensing details.\n",
        "- Transformers provides model architectures, tokenizers, and generation utilities.\n",
        "- Key building blocks: tokenizers (text -> ids), models (ids -> logits), and generation (sampling/decoding).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f99c7c0",
      "metadata": {
        "id": "1f99c7c0"
      },
      "source": [
        "### 1.2 Environment Setup\n",
        "\n",
        "Recommended packages:\n",
        "\n",
        "```bash\n",
        "%pip install -U transformers accelerate bitsandbytes huggingface_hub\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4616db89",
      "metadata": {
        "id": "4616db89"
      },
      "source": [
        "## 1.3 Authenticate with HuggingFace\n",
        "\n",
        "### Why Authenticate?\n",
        "\n",
        "Authentication with HuggingFace is **optional for most models** but recommended for:\n",
        "- **Gated models**: Some models require approval and authentication (e.g., Llama, Gemma)\n",
        "- **Private models**: Access your own private models or those shared with you\n",
        "- **Upload capabilities**: Push models, datasets, or files to your HuggingFace account\n",
        "\n",
        "### How to Get Your Token\n",
        "\n",
        "Follow these steps to create a HuggingFace access token:\n",
        "\n",
        "1. **Visit HuggingFace**: Go to [https://huggingface.co/](https://huggingface.co/)\n",
        "\n",
        "2. **Navigate to Settings**:\n",
        "   - Click on your profile picture (top right)\n",
        "   - Select **Settings** from the dropdown menu\n",
        "   - Click on **Access Tokens** in the left sidebar\n",
        "   \n",
        "   <img src=\"https://github.com/oh-scipe/llm-workshop26/blob/main/tutorials/assets/image.png?raw=1\" width=\"250\" alt=\"HuggingFace Access Tokens menu\"/>\n",
        "\n",
        "3. **Create New Token**:\n",
        "   - Click the **\"Create new token\"** button\n",
        "   - Give your token a descriptive name (e.g., \"Tutorial Notebook\")\n",
        "   - Choose token type:\n",
        "     - **Read**: For downloading models only (recommended for this tutorial)\n",
        "     - **Write**: For uploading models/datasets (not needed here)\n",
        "   - Click **\"Create token\"**\n",
        "   \n",
        "   <img src=\"https://github.com/oh-scipe/llm-workshop26/blob/main/tutorials/assets/image-1.png?raw=1\" width=\"500\" alt=\"Create new token dialog\"/>\n",
        "\n",
        "4. **Copy Your Token**:\n",
        "   - Copy the generated token immediately (it won't be shown again)\n",
        "   - Keep it secure - treat it like a password!\n",
        "\n",
        "### Run the Cell Below\n",
        "\n",
        "Run the next cell and paste your token when prompted. Alternatively, you can set the `HF_TOKEN` environment variable before starting Jupyter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ff7a86f6",
      "metadata": {
        "id": "ff7a86f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "405462ef25df48e9985b8ed36f522206",
            "c1828ecaea414febbd407c51208289a2",
            "1dfc4055c7014ff7ad64b11929f224d1",
            "600efadf002a4c92b4a9b69379211e54",
            "8ac6d7d9eb3d48ba863002328254e05d",
            "6ca297e5cda74924b2ec3083bc4469a8",
            "b40d0ea63dc841059eb894f9de2615d1",
            "29848bd59ad64b48b1eb6c61ca4057a4",
            "90135eaa6e154e49985b7e2991c358da",
            "866eb96dde224ee8a09d096f69f72c6e",
            "316433179ae54d95841c9a8d1c5c3727",
            "a30b3f11ae804955a18d9ecfedecf549",
            "15c85c628bf14409aeda451142ea55d0",
            "52eb280b115d4b14adef1b424229c480",
            "477ff87853354712b8b937e60f895664",
            "e214606c7b914b549b4b0b555c8a6d59",
            "040eb506fe6f42fc8b5369a5be30dbec",
            "e30284a23c32487daa2338060a8f0b3d",
            "d7dd60a8ba3449e29d1c5648878dad36",
            "d1c3f0f537644a4d80a75afd88151725"
          ]
        },
        "outputId": "5dd0b489-b608-41da-98ee-456a797be81d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "405462ef25df48e9985b8ed36f522206"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Authenticate with HuggingFace\n",
        "# This will prompt you to paste your token in a text box\n",
        "from huggingface_hub import login\n",
        "\n",
        "login()\n",
        "\n",
        "# Alternative: Set token via environment variable\n",
        "# import os\n",
        "# os.environ['HF_TOKEN'] = 'your_token_here'\n",
        "# login(token=os.environ['HF_TOKEN'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "57d73040",
      "metadata": {
        "id": "57d73040",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47e14444-4ce0-4a5e-8448-1f2bee41e395"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.12\n",
            "Torch: 2.9.0+cu126\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n",
            "Capability: (7, 5)\n",
            "BF16 support: True\n"
          ]
        }
      ],
      "source": [
        "# Check environment\n",
        "import platform\n",
        "import torch\n",
        "\n",
        "print(\"Python:\", platform.python_version())\n",
        "print(\"Torch:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "    print(\"Capability:\", torch.cuda.get_device_capability(0))\n",
        "    print(\"BF16 support:\", torch.cuda.is_bf16_supported())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c75a1451",
      "metadata": {
        "id": "c75a1451"
      },
      "source": [
        "## Part 2: General Inference with LLMs\n",
        "\n",
        "### 2.1 Define Model Constants and Basic Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d418773",
      "metadata": {
        "id": "2d418773"
      },
      "outputs": [],
      "source": [
        "# Set up torch for optimal performance\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cuda.matmul.fp32_precision = \"tf32\"\n",
        "    torch.backends.cudnn.conv.fp32_precision = \"tf32\"\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Model identifiers\n",
        "MODEL_INSTRUCT = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
        "MODEL_THINKING = \"Qwen/Qwen3-4B-Thinking-2507\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7cb7801",
      "metadata": {
        "id": "a7cb7801"
      },
      "source": [
        "### 2.2 Load Model and Tokenizer\n",
        "\n",
        "Load the instruct model directly for basic inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb996130",
      "metadata": {
        "id": "cb996130"
      },
      "outputs": [],
      "source": [
        "# Import transformers components\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_id = MODEL_INSTRUCT\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_id,\n",
        "    use_fast=True,\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    dtype=torch.bfloat16,\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "model.eval()\n",
        "if tokenizer.pad_token_id is None:\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2646c93",
      "metadata": {
        "id": "f2646c93"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04033270",
      "metadata": {
        "id": "04033270"
      },
      "source": [
        "### 2.3 Basic Chat Inference\n",
        "\n",
        "Create helper functions for formatting messages and generating responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70d534da",
      "metadata": {
        "id": "70d534da"
      },
      "outputs": [],
      "source": [
        "def format_messages(user_prompt, system_prompt=\"You are a helpful assistant.\"):\n",
        "    \"\"\"Format messages for chat models.\"\"\"\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt},\n",
        "    ]\n",
        "\n",
        "\n",
        "def generate_chat(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    messages,\n",
        "    max_new_tokens=256,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    do_sample=True,\n",
        "    **kwargs,\n",
        "):\n",
        "    \"\"\"Generate a chat response.\"\"\"\n",
        "    input_ids = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt=True,\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(model.device)\n",
        "\n",
        "    gen_kwargs = dict(\n",
        "        input_ids=input_ids,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=do_sample,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        **kwargs,\n",
        "    )\n",
        "    if do_sample:\n",
        "        gen_kwargs.update({\"temperature\": temperature, \"top_p\": top_p})\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        output_ids = model.generate(**gen_kwargs)\n",
        "\n",
        "    gen_ids = output_ids[0, input_ids.shape[-1] :]\n",
        "    return tokenizer.decode(gen_ids, skip_special_tokens=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3690db2b",
      "metadata": {
        "id": "3690db2b"
      },
      "outputs": [],
      "source": [
        "# Try a basic chat completion\n",
        "messages = format_messages(\n",
        "    \"Summarize the HuggingFace Hub in 2 sentences.\",\n",
        "    system_prompt=\"You are a concise assistant.\",\n",
        ")\n",
        "\n",
        "print(generate_chat(model, tokenizer, messages, max_new_tokens=120))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91c35c0b",
      "metadata": {
        "id": "91c35c0b"
      },
      "source": [
        "### 2.4 Streaming Responses\n",
        "\n",
        "For longer responses, streaming provides better UX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "689fcd20",
      "metadata": {
        "id": "689fcd20"
      },
      "outputs": [],
      "source": [
        "# Import streaming utilities\n",
        "from threading import Thread\n",
        "from transformers import TextIteratorStreamer\n",
        "\n",
        "\n",
        "def stream_chat(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    messages,\n",
        "    max_new_tokens=256,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "):\n",
        "    \"\"\"Stream chat responses token by token.\"\"\"\n",
        "    input_ids = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt=True,\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(model.device)\n",
        "\n",
        "    streamer = TextIteratorStreamer(tokenizer, skip_special_tokens=True)\n",
        "    generation_kwargs = dict(\n",
        "        input_ids=input_ids,\n",
        "        streamer=streamer,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=True,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "\n",
        "    def _run_generate():\n",
        "        model.eval()\n",
        "        with torch.inference_mode():\n",
        "            model.generate(**generation_kwargs)\n",
        "\n",
        "    thread = Thread(target=_run_generate, daemon=True)\n",
        "    thread.start()\n",
        "\n",
        "    try:\n",
        "        for text in streamer:\n",
        "            print(text, end=\"\", flush=True)\n",
        "    finally:\n",
        "        thread.join()\n",
        "\n",
        "        # Explicitly drop local refs that may include CUDA tensors\n",
        "        del input_ids, generation_kwargs, streamer, thread\n",
        "        import gc\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            torch.cuda.synchronize()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4f4b868",
      "metadata": {
        "id": "f4f4b868"
      },
      "outputs": [],
      "source": [
        "messages = format_messages(\"Write a short poem about GPUs and data centers.\")\n",
        "stream_chat(model, tokenizer, messages, max_new_tokens=120, temperature=0.8, top_p=0.95)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1fc066c",
      "metadata": {
        "id": "b1fc066c"
      },
      "source": [
        "### 2.5 Practical Tasks\n",
        "\n",
        "Test the model on various common LLM tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67366250",
      "metadata": {
        "id": "67366250"
      },
      "outputs": [],
      "source": [
        "# Run various practical tasks\n",
        "practical_tasks = {\n",
        "    \"translation\": \"Translate to Spanish: The model scales efficiently on modern GPUs.\",\n",
        "    \"summarization\": (\n",
        "        \"Summarize in 3 bullets: HuggingFace provides open-source NLP libraries, a model hub, \"\n",
        "        \"and tools for training and deployment across research and production.\"\n",
        "    ),\n",
        "    \"general_qa\": \"Q: What is the main purpose of the Transformers library?\",\n",
        "    \"planning\": \"Plan a 4-step rollout for an internal LLM pilot at a company.\",\n",
        "    \"code_explanation\": \"Explain what this Python does: for i in range(3): print(i*i)\",\n",
        "    \"code_generation\": \"Write a Python function that checks if a string is a palindrome.\",\n",
        "}\n",
        "\n",
        "for name, prompt in practical_tasks.items():\n",
        "    messages = format_messages(prompt)\n",
        "    output = generate_chat(model, tokenizer, messages, max_new_tokens=200)\n",
        "    print(f\"=== {name} ===\")\n",
        "    print(output)\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd57a4db",
      "metadata": {
        "id": "bd57a4db"
      },
      "source": [
        "### 2.6 Experiment: Compare Generation Parameters\n",
        "\n",
        "See how temperature and sampling affect outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5b51364",
      "metadata": {
        "id": "d5b51364"
      },
      "outputs": [],
      "source": [
        "# Compare different generation settings\n",
        "prompt = \"Write a two-sentence pitch for a collaborative AI research lab.\"\n",
        "\n",
        "settings = [\n",
        "    {\"name\": \"deterministic\", \"do_sample\": False},\n",
        "    {\"name\": \"balanced\", \"do_sample\": True, \"temperature\": 0.7, \"top_p\": 0.9},\n",
        "    {\"name\": \"creative\", \"do_sample\": True, \"temperature\": 1.1, \"top_p\": 0.95},\n",
        "]\n",
        "\n",
        "for cfg in settings:\n",
        "    messages = format_messages(prompt, system_prompt=\"You are a marketing copywriter.\")\n",
        "    output = generate_chat(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        messages,\n",
        "        max_new_tokens=120,\n",
        "        **{k: v for k, v in cfg.items() if k != \"name\"},\n",
        "    )\n",
        "    print(f\"=== {cfg['name']} ===\")\n",
        "    print(output)\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f493d703",
      "metadata": {
        "id": "f493d703"
      },
      "source": [
        "### 2.7 Baseline Tests for Model Comparison\n",
        "\n",
        "Run these tests to compare with thinking models later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4c00eb3",
      "metadata": {
        "id": "a4c00eb3"
      },
      "outputs": [],
      "source": [
        "# Run comparison prompts on non-thinking model\n",
        "comparison_prompts = {\n",
        "    \"math\": \"Solve: If a train travels 120 km in 1.5 hours, what is its average speed?\",\n",
        "    \"reasoning\": \"You have 3 boxes: apples, oranges, and mixed. All labels are wrong. \"\n",
        "    \"Pick one fruit to identify all boxes. Explain.\",\n",
        "    \"analysis\": \"Compare pros and cons of deploying an LLM on-prem vs in the cloud.\",\n",
        "}\n",
        "\n",
        "non_thinking_results = {}\n",
        "for name, prompt in comparison_prompts.items():\n",
        "    messages = format_messages(prompt, system_prompt=\"You are a precise assistant.\")\n",
        "    non_thinking_results[name] = generate_chat(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        messages,\n",
        "        max_new_tokens=200,\n",
        "        do_sample=False,\n",
        "    )\n",
        "\n",
        "print(\"Baseline results saved for comparison with thinking model.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1343b968",
      "metadata": {
        "id": "1343b968"
      },
      "source": [
        "## Part 3: Advanced Reasoning with Thinking Models\n",
        "\n",
        "Thinking models expose internal reasoning steps for complex tasks. Let's switch to the thinking version and compare."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd646551",
      "metadata": {
        "id": "cd646551"
      },
      "source": [
        "### 3.1 Unload Current Model and Load Thinking Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0201bb40",
      "metadata": {
        "id": "0201bb40"
      },
      "outputs": [],
      "source": [
        "# Free up memory before loading the thinking model\n",
        "import gc\n",
        "\n",
        "def print_cuda_memory(tag):\n",
        "    if torch.cuda.is_available():\n",
        "        free, total = torch.cuda.mem_get_info()\n",
        "        used = total - free\n",
        "        print(f\"[{tag}] CUDA memory:\")\n",
        "        print(f\"  Used : {used / 1024**3:.2f} GB\")\n",
        "        print(f\"  Free : {free / 1024**3:.2f} GB\")\n",
        "        print(f\"  Total: {total / 1024**3:.2f} GB\")\n",
        "    else:\n",
        "        print(\"CUDA not available.\")\n",
        "\n",
        "# Before cleanup\n",
        "print_cuda_memory(\"Before cleanup\")\n",
        "\n",
        "# Cleanup\n",
        "model.to('cpu')\n",
        "del model, tokenizer\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(\"Memory cleared.\")\n",
        "\n",
        "# After cleanup\n",
        "print_cuda_memory(\"After cleanup\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c855fd4",
      "metadata": {
        "id": "6c855fd4"
      },
      "outputs": [],
      "source": [
        "# Load the thinking model\n",
        "\n",
        "model_id = MODEL_THINKING\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_id,\n",
        "    use_fast=True,\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    dtype=torch.bfloat16,\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "model.eval()\n",
        "if tokenizer.pad_token_id is None:\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bd55816",
      "metadata": {
        "id": "8bd55816"
      },
      "outputs": [],
      "source": [
        "model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83abd644",
      "metadata": {
        "id": "83abd644"
      },
      "source": [
        "### 3.2 Run Same Tests with Thinking Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9e1b074",
      "metadata": {
        "id": "d9e1b074"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Run same prompts with thinking model\n",
        "thinking_results = {}\n",
        "for name, prompt in comparison_prompts.items():\n",
        "    messages = format_messages(prompt, system_prompt=\"You are a reasoning assistant.\")\n",
        "    thinking_results[name] = generate_chat(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        messages,\n",
        "        max_new_tokens=500,\n",
        "        do_sample=False,\n",
        "    )\n",
        "\n",
        "print(\"Thinking model results collected.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc1b9762",
      "metadata": {
        "id": "cc1b9762"
      },
      "source": [
        "### 3.3 Compare Results Side-by-Side"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deaafa7c",
      "metadata": {
        "id": "deaafa7c"
      },
      "outputs": [],
      "source": [
        "# Display comparison\n",
        "for name in comparison_prompts:\n",
        "    print(f\"=== {name} ===\")\n",
        "    print(\"Non-thinking:\")\n",
        "    print(non_thinking_results[name])\n",
        "    print(\"\\nThinking:\")\n",
        "    print(thinking_results[name])\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "405462ef25df48e9985b8ed36f522206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_b40d0ea63dc841059eb894f9de2615d1"
          }
        },
        "c1828ecaea414febbd407c51208289a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29848bd59ad64b48b1eb6c61ca4057a4",
            "placeholder": "​",
            "style": "IPY_MODEL_90135eaa6e154e49985b7e2991c358da",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "1dfc4055c7014ff7ad64b11929f224d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_866eb96dde224ee8a09d096f69f72c6e",
            "placeholder": "​",
            "style": "IPY_MODEL_316433179ae54d95841c9a8d1c5c3727",
            "value": ""
          }
        },
        "600efadf002a4c92b4a9b69379211e54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_a30b3f11ae804955a18d9ecfedecf549",
            "style": "IPY_MODEL_15c85c628bf14409aeda451142ea55d0",
            "value": true
          }
        },
        "8ac6d7d9eb3d48ba863002328254e05d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_52eb280b115d4b14adef1b424229c480",
            "style": "IPY_MODEL_477ff87853354712b8b937e60f895664",
            "tooltip": ""
          }
        },
        "6ca297e5cda74924b2ec3083bc4469a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e214606c7b914b549b4b0b555c8a6d59",
            "placeholder": "​",
            "style": "IPY_MODEL_040eb506fe6f42fc8b5369a5be30dbec",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "b40d0ea63dc841059eb894f9de2615d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "29848bd59ad64b48b1eb6c61ca4057a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90135eaa6e154e49985b7e2991c358da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "866eb96dde224ee8a09d096f69f72c6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "316433179ae54d95841c9a8d1c5c3727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a30b3f11ae804955a18d9ecfedecf549": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15c85c628bf14409aeda451142ea55d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52eb280b115d4b14adef1b424229c480": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "477ff87853354712b8b937e60f895664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "e214606c7b914b549b4b0b555c8a6d59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "040eb506fe6f42fc8b5369a5be30dbec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e30284a23c32487daa2338060a8f0b3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7dd60a8ba3449e29d1c5648878dad36",
            "placeholder": "​",
            "style": "IPY_MODEL_d1c3f0f537644a4d80a75afd88151725",
            "value": "Connecting..."
          }
        },
        "d7dd60a8ba3449e29d1c5648878dad36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1c3f0f537644a4d80a75afd88151725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}